# ============================================================================================================================================= #
#Imports
import cv2
import numpy as np
# ============================================================================================================================================= #

# ============================================================================================================================================= #
#Globals:
batch_dir = r'C:\Users\Naftalis\Desktop\Computer Vision\Project\cifar-10-batches-py'
data_1 = batch_dir + '\\' + r'data_batch_1'
# ============================================================================================================================================= #

# ============================================================================================================================================= #
# dict = {data : lables}
# data = 10000*3072 numpy array of uint8
#   Each row of the array stores a 32x32 colour image
#   The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue
#   The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image
# lables =  list of 10000 numbers in the range 0-9
#   The number at index i indicates the label of the ith image in the array data
# ============================================================================================================================================= #
# The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:
#   label_names = 10-element list which gives meaningful names to the numeric labels in the labels array described above.
#   For example, label_names[0] == "airplane", label_names[1] == "automobile", etc.
# ============================================================================================================================================= #
def unpickle(file, print_msg = False):
    if print_msg:
        print 'unpicking training set images'
        
    import cPickle
    with open(file, 'rb') as fo:
        dict = cPickle.load(fo)
    return dict

# ============================================================================================================================================= #
# input: array of 3072 elements
# ============================================================================================================================================= #
def img_2_RGB_cv2_format(im, print_msg = False):
    if print_msg:
        print 'reshaping image to RGB format (32*32*3)'
        
    mat = np.zeros((32,32,3), np.uint8)
    for i in range(32*32*3):
        mat[(i % (32*32)) // 32][i % 32][i // (32*32)] = im[i]
    return mat

# ============================================================================================================================================= #
# input: image list, heading (optional), delay [mili-seconds] (optional)
# ============================================================================================================================================= #
def show_img(i, heading = '', delay = 600):
    cv2.imshow(heading, i) 
    cv2.waitKey(delay)
    cv2.destroyAllWindows()

# ============================================================================================================================================= #
# input: 2 images, threshold [0.0 : 1.0] (how tight should the matches be)
# ============================================================================================================================================= #
def bf_matcher(im1, im2, th = 0.75):
    pass
    # TO DO
    # move the bf code into this function
    # try the 2nd method from https://docs.opencv.org/3.1.0/da/df5/tutorial_py_sift_intro.html
    # mission - do SIFT on all images


def my_main():
    d = unpickle(data_1)
    from matplotlib import pyplot as plt
    images = d.values()[0]
    labels = d.values()[1]
    
    labeled_images = [[] for i in range(10)]
    descriptors = [[] for i in range(10)]
    
    for i in range(len(images) // 100):
        labeled_images[labels[i]] += [images[i]]
    
    sift = cv2.xfeatures2d.SIFT_create()
    
    for label in enumerate(labeled_images):
        for img in label[1]:
            kp,des = sift.detectAndCompute(img_2_RGB_cv2_format(img), None)
            descriptors[label[0]] += [des] #kp are irelevant?

    print descriptors
    
    del descriptors
    del images
    del labels
    return
        
    sift = cv2.xfeatures2d.SIFT_create()
    for i in range(3):
        im = img_2_RGB_cv2_format(images[i])
        kp = sift.detect(im, None)
        im = cv2.drawKeypoints(im,kp,im)
        cv2.imwrite('sift_keypoints.jpg',im)
        im=cv2.drawKeypoints(im,kp,im,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)        
        plt.imshow(im),plt.show()
        plt.imshow(img_2_RGB_cv2_format(images[i])),plt.show()
    
              

            
    


#    for i in range(10):
 #       show_img(img_2_RGB_cv2_format(training_set_images[i]), delay = 400)

    #print 'RGB images -> grayscale'
    
    
    
    
    
my_main()



















