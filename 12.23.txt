# ============================================================================================================================================= #
#Imports
import cv2
import numpy as np
import time
import cPickle
from sklearn.svm import SVC 
from sklearn.metrics import confusion_matrix
# ============================================================================================================================================= #
# change the paths when running from another enviorment!!
# ============================================================================================================================================= #
#Globals:

start_time = time.time()

# number of images to check. For testing. 10000 is the value for a real run
N = 10000

# paths
batch_dir = r'C:\Users\Naftalis\Desktop\Computer Vision\Project\cifar-10-batches-py'
data_1 = batch_dir + '\\' + r'data_batch_1'
data_2 = batch_dir + '\\' + r'data_batch_2'
data_3 = batch_dir + '\\' + r'data_batch_3'
data_4 = batch_dir + '\\' + r'data_batch_4'
data_5 = batch_dir + '\\' + r'data_batch_5'
data_batch = [data_1, data_2, data_3, data_4, data_5]
test = batch_dir + '\\' + r'test_batch'
clf_name = r"C:\Users\Naftalis\Desktop\Computer Vision\Project\clf_dense"

# labels for prediction
predictions = []
actuals = []

# ============================================================================================================================================= #

# ============================================================================================================================================= #
# dict = {data : lables}
# data = 10000*3072 numpy array of uint8
#   Each row of the array stores a 32x32 colour image
#   The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue
#   The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image
# lables =  list of 10000 numbers in the range 0-9
#   The number at index i indicates the label of the ith image in the array data
# ============================================================================================================================================= #
# The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:
#   label_names = 10-element list which gives meaningful names to the numeric labels in the labels array described above.
#   For example, label_names[0] == "airplane", label_names[1] == "automobile", etc.
# ============================================================================================================================================= #
def unpickle(file, print_msg = False):
    if print_msg:
        print 'starting unpickling {}...'.format(file[file.rfind('\\')+1:])
        
    with open(file, 'rb') as fo:
        dict = cPickle.load(fo)
        
    if print_msg:
        print 'finished unpickling {}...'.format(file[file.rfind('\\')+1:])
        print '#'*50 
    return dict

# ============================================================================================================================================= #
# input: array of 3072 elements
# ============================================================================================================================================= #
def img_2_RGB(im, print_msg = False):
    if print_msg:
        print 'reshaping image to RGB format (32*32*3)'
        
    mat = np.zeros((32,32,3), np.uint8)
    for i in range(32*32*3):
        mat[(i % (32*32)) // 32][i % 32][i // (32*32)] = im[i]
    return mat

# ============================================================================================================================================= #
# input: image list, heading (optional), delay [mili-seconds] (optional)
# for testing. Not used
# ============================================================================================================================================= #
def show_img(i, heading = '', delay = 1000):
    cv2.imshow(heading, i) 
    cv2.waitKey(delay)
    cv2.destroyAllWindows()
# ============================================================================================================================================= #
# finds good key-points for the classifier using one of many hueristics
# ============================================================================================================================================= #
def find_good_kp(hueristic = 'dense', num_of_images_to_sum = 3):
    #print num_of_test_images
    tst = unpickle(test)
    sift = cv2.xfeatures2d.SIFT_create()
    tst_images = tst.values()[0]
    good_kp = []
    
    # find best image (with most KP), and use it
    if hueristic == 'richest image':
        max_kp = 0
        for im in enumerate(tst_images):
            im = img_2_RGB(im[1])
            kp = sift.detect(im, None)
            if len(kp) > max_kp:
                max_kp = len(kp)
                good_kp = kp
              
    # use predetermined locations and size for KP (trying to catch good KP in the image)                
    elif hueristic == 'dense':
        W,H,size = 32,32,4
        margin = 1
        step = 5
        for w in range(margin, W - margin, step):
            for h in range(margin, H - margin, step):
                good_kp.append(cv2.KeyPoint(w,h,size))        
        
    # for testing. Not used
    elif hueristic == 'specific image':
        for im in enumerate(tst_images):
            if im[0] == 65:
                im = img_2_RGB(im[1])
                good_kp = sift.detect(im, None)
                show_img(cv2.resize(im, (0,0),fx=10,fy=10),delay = 2500)
                break
    
    # takes much longer time with no significant improvement. Not used            
    elif hueristic == 'several good images':  
        count = 0
        for im in enumerate(tst_images):
            img = img_2_RGB(im[1])
            kp = sift.detect(img, None)
            if len(kp) >= 25:
                good_kp += kp
                count += 1
            if count == num_of_images_to_sum:
                break
            
    del tst   
    del tst_images
    del sift
    print '# of descriptors {}'.format(len(good_kp))
    return good_kp

# ============================================================================================================================================= #
# loads a classifier from file and scores it.
# input:    tst_X               - the test cases
#           tst_relevant_labels - the true labels
# output: classifier prediction
# ============================================================================================================================================= #
def load_and_predict(file, tst_X, tst_relevant_labels):
    print '#' *50, '\n'
    load_start_time = time.time()
    with open(file, 'rb') as fo:
        clf = cPickle.load(fo)
        print 'loading took {} seconds'.format(time.time() - load_start_time)
        score_time = time.time()
        print 'Rate = {}% ({} seconds)'.format(100*clf.score(tst_X,tst_relevant_labels), time.time() - score_time)
        print '#' *50, '\n'
        return confusion_matrix(tst_relevant_labels, clf.predict(tst_X).flatten())

# ============================================================================================================================================= #
# create SIFT
# unpickle test images
# find KP with find_good_kp()
# use them to find descriptors
# insert to np.array
# ============================================================================================================================================= #
tst_start_time = time.time()

sift = cv2.xfeatures2d.SIFT_create()

tst = unpickle(test)    
tst_images = tst.values()[0][:N]
tst_labels = tst.values()[1][:N]
  
tst_relevant_sized_descriptors = []
tst_relevant_labels = [] 

tst_kp = find_good_kp(hueristic = 'dense')

for im,lb in zip(tst_images, tst_labels):
    im = img_2_RGB(im)
    kp,ds = sift.compute(im, tst_kp)
    
    tst_relevant_sized_descriptors.append(ds.flatten())
    tst_relevant_labels.append(lb)
        
tst_X = np.array(tst_relevant_sized_descriptors)
test_size = len(tst_X)

print '#' *50, '\n', 'test images - phase 1: {} seconds'.format(time.time() - tst_start_time)
# ============================================================================================================================================= #
# unpickle each image batch and save into lists
# ============================================================================================================================================= #
batch_start_time = time.time()

relevant_sized_descriptors = []
relevant_labels = []

for data in data_batch:
    d = unpickle(data)

    images = d.values()[0][:N]
    labels = d.values()[1][:N]
    
    for im,lb in zip(images, labels):
        im = img_2_RGB(im)
        kp,ds = sift.compute(im, tst_kp)
        relevant_sized_descriptors.append(ds.flatten())
        relevant_labels.append(lb)

print '#' *50, '\n', 'training images - phase 2: {} seconds'.format(time.time() - batch_start_time)
# ============================================================================================================================================= #
# prepare data for classification
# create classifier
# fit data
# pickle
# ============================================================================================================================================= #
fit_start_time = time.time()

X = np.array(relevant_sized_descriptors)
training_size = len(X)
y = np.array(relevant_labels)

# after many tests, this was found to be best classifier
clf = SVC(C = 0.001, kernel='poly', degree = 3, gamma = 0.001, cache_size = 1000)
clf.fit(X,y)

# save classifier to file
pickle_start_time = time.time()
cPickle.dump(clf, open(clf_name, "wb" ),  protocol = cPickle.HIGHEST_PROTOCOL) 
pickle_end_time = time.time()

print '#' *50, '\n', 'fitting - phase 3: {} seconds (pickling took {})'.format(time.time() - fit_start_time, pickle_end_time - pickle_start_time)
# ============================================================================================================================================= #      
# clean-up
# ============================================================================================================================================= #      
clean_start_time = time.time()

del relevant_sized_descriptors
del relevant_labels
del X
del y
del d
del clf
del images
del labels
del sift

print '#' *50, '\n', 'clean up - phase 4: {} seconds '.format(time.time() - clean_start_time)
# ============================================================================================================================================= #      
# load and predict
# ============================================================================================================================================= #
prediction_start_time = time.time()
confusion_matrix = load_and_predict(clf_name, tst_X, tst_relevant_labels)

del tst_X
del tst_relevant_labels
print '#' *50, '\n', 'prediction: {} seconds '.format(time.time() - prediction_start_time)
# ============================================================================================================================================= #      
# end :-)
# ============================================================================================================================================= #
print('\a')
print 'Done!\n\n'
print '#' *50, '\n', 'total: {} seconds '.format(time.time() - start_time)
print confusion_matrix